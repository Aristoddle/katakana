{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107261\n",
      "                         0              1\n",
      "11206           Dorogobuzh         ドロゴブージ\n",
      "80376         Gail Hopkins      ゲイル・ホプキンス\n",
      "38108              Novatek          ノヴァテク\n",
      "29960      Gyula Cseszneky     チェスネキー・ジュラ\n",
      "22295  Occhieppo Superiore  オッキエッポ・スペリオーレ\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/joined_titles.csv', header=None)\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "\n",
    "print(len(data))\n",
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'dorogobuzh', u'gail hopkins', u'novatek']\n",
      "[u'\\u30c9\\u30ed\\u30b4\\u30d6\\u30fc\\u30b8', u'\\u30b2\\u30a4\\u30eb\\u30fb\\u30db\\u30d7\\u30ad\\u30f3\\u30b9', u'\\u30ce\\u30f4\\u30a1\\u30c6\\u30af']\n"
     ]
    }
   ],
   "source": [
    "data_input = [s.decode('utf-8').lower() for s in data[0]]\n",
    "data_output = [s.decode('utf-8') for s in data[1]]\n",
    "\n",
    "print(data_input[0:3])\n",
    "print(data_output[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42904\n",
      "10726\n"
     ]
    }
   ],
   "source": [
    "data_size = len(data)\n",
    "\n",
    "# We will use the first 0-60th %-tile (60%) of data for the training\n",
    "training_input  = data_input[data_size*0/100:data_size*60/100]\n",
    "training_output = data_output[data_size*0/100:data_size*60/100]\n",
    "\n",
    "# We will use the first 60-70th %-tile (10%) of data for the training\n",
    "validation_input = data_input[data_size*60/100:data_size*70/100]\n",
    "validation_output = data_output[data_size*60/100:data_size*70/100]\n",
    "\n",
    "print(len(training_input))\n",
    "print(len(validation_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding character input\n",
    "\n",
    "We will create a character dictionary and encode the title from a string (a sequence of character) into a sequence of IDs. We will also create the reverse dictionary that will be used for getting the result later.\n",
    "\n",
    "Note that in practice, we must not build the dictionary from all data (`data_input` and `data_output`), but only use the training set (`training_input` and `training_output`). We also have to handle out-of-dictionary characters. However, for now, I will skip that part.\n",
    "\n",
    "Note:\n",
    "- We will use 0 for padding and 1 for 'START'. So, `count` starts from 2. \n",
    "- This is to take advantage of `mask_zero=True` feature for Embedding Layer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English character dict size: 54\n",
      "Katakana character dict size: 89\n",
      "[(u'j', 35), (u'u', 44), (u' ', 5), (u'z', 50), (u's', 42)]\n",
      "[(1, 'START'), (2, u'\\xea'), (3, u'\\u017c'), (4, u'\\u0175'), (5, u' ')]\n"
     ]
    }
   ],
   "source": [
    "START_CHAR_CODE = 1\n",
    "\n",
    "def encode_characters(titles):\n",
    "    count = 2\n",
    "    encoding = {}\n",
    "    decoding = {1: 'START'}\n",
    "    for c in set([c for title in titles for c in title]):\n",
    "        encoding[c] = count\n",
    "        decoding[count] = c\n",
    "        count += 1\n",
    "    return encoding, decoding, count\n",
    "\n",
    "\n",
    "input_encoding, input_decoding, input_dict_size = encode_characters(data_input)\n",
    "output_encoding, output_decoding, output_dict_size = encode_characters(data_output)\n",
    "\n",
    "\n",
    "print('English character dict size:', input_dict_size)\n",
    "print('Katakana character dict size:', output_dict_size)\n",
    "\n",
    "print(input_encoding.items()[0:5])\n",
    "print(input_decoding.items()[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Transforming the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input [[ 29.  38.  43. ...,   0.   0.   0.]\n",
      " [ 30.  25.  32. ...,   0.   0.   0.]\n",
      " [ 39.  38.  47. ...,   0.   0.   0.]\n",
      " ..., \n",
      " [ 34.  25.  45. ...,   0.   0.   0.]\n",
      " [ 42.  32.  37. ...,   0.   0.   0.]\n",
      " [ 35.  38.  42. ...,   0.   0.   0.]]\n",
      "output [[ 57.  66.  29. ...,   0.   0.   0.]\n",
      " [ 72.  25.  21. ...,   0.   0.   0.]\n",
      " [ 79.  45.  47. ...,   0.   0.   0.]\n",
      " ..., \n",
      " [ 50.  19.  53. ...,   0.   0.   0.]\n",
      " [  8.  21.  36. ...,   0.   0.   0.]\n",
      " [ 30.  20.   8. ...,   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "def transform(encoding, data, vector_size):\n",
    "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(min(len(data[i]), vector_size)):\n",
    "            transformed_data[i][j] = encoding[data[i][j]]\n",
    "    return transformed_data\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n",
    "\n",
    "encoded_training_input = transform(input_encoding, training_input, vector_size=INPUT_LENGTH)\n",
    "encoded_training_output = transform(output_encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
    "encoded_validation_input = transform(input_encoding, validation_input, vector_size=INPUT_LENGTH)\n",
    "encoded_validation_output = transform(output_encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('input', encoded_training_input)\n",
    "print('output', encoded_training_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "First, we will use [Embedding layer](https://keras.io/layers/embeddings/) to transform input char-id sequence into dense vectors.  \n",
    "\n",
    "The input vectors will be passed to a [Recurrent layer](https://keras.io/layers/recurrent/) (we use LSTM) that will transform the vectors of each input character to a single output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64)\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder = Embedding(input_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = LSTM(64)(encoder)\n",
    "\n",
    "print(encoder.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Our decoder generate Katakana sequence (as a softmax prediction) on characrter at the time. Every generated output at decoding step will be passed back as an input of the decoder to generate the next output.\n",
    "\n",
    "Similar to the encoder, the input will be passed to an Embedding layer to transform the input into dense vectors and pass them to LSTM.\n",
    "\n",
    "We will use the encoder's output to initialize decoder state (`initial_state`).\n",
    "\n",
    "The final layer will be (time distributed) Dense layer that will produce the softmax prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20, 89)\n"
     ]
    }
   ],
   "source": [
    "decoder = Embedding(output_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "\n",
    "decoder = LSTM(64, return_sequences=True)(decoder, initial_state=[encoder, encoder])\n",
    "decoder = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(decoder)\n",
    "\n",
    "print(decoder.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input [[ 29.  38.  43.  38.  30.  38.  27.  44.  50.  33.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.]]\n",
      "decoder input [[  1.  57.  66.  29.  81.  46.  30.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.]]\n",
      "decoder output [[57 66 29 81 46 30  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "decoder output (one-hot) [[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 1.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...,  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Encoder Input\n",
    "training_encoder_input = encoded_training_input\n",
    "\n",
    "# Decoder Input (need padding py START_CHAR_CODE)\n",
    "training_decoder_input = np.zeros_like(encoded_training_output)\n",
    "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
    "training_decoder_input[:, 0] = START_CHAR_CODE\n",
    "\n",
    "# Decoder Output (one-hot encode)\n",
    "training_decoder_output = np.eye(output_dict_size)[encoded_training_output.astype('int')]\n",
    "\n",
    "\n",
    "print('encoder input', training_encoder_input[:1])\n",
    "print('decoder input', training_decoder_input[:1])\n",
    "print('decoder output', training_decoder_output[:1].argmax(axis=2))\n",
    "print('decoder output (one-hot)', training_decoder_output[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_encoder_input = encoded_validation_input\n",
    "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
    "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
    "validation_decoder_input[:, 0] = START_CHAR_CODE\n",
    "validation_decoder_output = np.eye(output_dict_size)[encoded_validation_output.astype('int')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42904 samples, validate on 10726 samples\n",
      "Epoch 1/60\n",
      "105s - loss: 0.0483 - val_loss: 0.0441\n",
      "Epoch 2/60\n",
      "99s - loss: 0.0422 - val_loss: 0.0410\n",
      "Epoch 3/60\n",
      "100s - loss: 0.0399 - val_loss: 0.0396\n",
      "Epoch 4/60\n",
      "102s - loss: 0.0385 - val_loss: 0.0380\n",
      "Epoch 5/60\n",
      "100s - loss: 0.0369 - val_loss: 0.0364\n",
      "Epoch 6/60\n",
      "97s - loss: 0.0352 - val_loss: 0.0347\n",
      "Epoch 7/60\n",
      "98s - loss: 0.0335 - val_loss: 0.0331\n",
      "Epoch 8/60\n",
      "98s - loss: 0.0319 - val_loss: 0.0316\n",
      "Epoch 9/60\n",
      "104s - loss: 0.0304 - val_loss: 0.0300\n",
      "Epoch 10/60\n",
      "100s - loss: 0.0289 - val_loss: 0.0288\n",
      "Epoch 11/60\n",
      "99s - loss: 0.0278 - val_loss: 0.0277\n",
      "Epoch 12/60\n",
      "99s - loss: 0.0268 - val_loss: 0.0269\n",
      "Epoch 13/60\n",
      "102s - loss: 0.0259 - val_loss: 0.0263\n",
      "Epoch 14/60\n",
      "104s - loss: 0.0252 - val_loss: 0.0257\n",
      "Epoch 15/60\n",
      "103s - loss: 0.0246 - val_loss: 0.0251\n",
      "Epoch 16/60\n",
      "101s - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 17/60\n",
      "98s - loss: 0.0236 - val_loss: 0.0242\n",
      "Epoch 18/60\n",
      "98s - loss: 0.0231 - val_loss: 0.0238\n",
      "Epoch 19/60\n",
      "99s - loss: 0.0227 - val_loss: 0.0236\n",
      "Epoch 20/60\n",
      "98s - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 21/60\n",
      "99s - loss: 0.0220 - val_loss: 0.0228\n",
      "Epoch 22/60\n",
      "99s - loss: 0.0216 - val_loss: 0.0226\n",
      "Epoch 23/60\n",
      "99s - loss: 0.0214 - val_loss: 0.0224\n",
      "Epoch 24/60\n",
      "98s - loss: 0.0211 - val_loss: 0.0221\n",
      "Epoch 25/60\n",
      "98s - loss: 0.0208 - val_loss: 0.0219\n",
      "Epoch 26/60\n",
      "99s - loss: 0.0206 - val_loss: 0.0217\n",
      "Epoch 27/60\n",
      "98s - loss: 0.0204 - val_loss: 0.0216\n",
      "Epoch 28/60\n",
      "98s - loss: 0.0202 - val_loss: 0.0215\n",
      "Epoch 29/60\n",
      "99s - loss: 0.0200 - val_loss: 0.0212\n",
      "Epoch 30/60\n",
      "98s - loss: 0.0198 - val_loss: 0.0211\n",
      "Epoch 31/60\n",
      "98s - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 32/60\n",
      "98s - loss: 0.0195 - val_loss: 0.0208\n",
      "Epoch 33/60\n",
      "100s - loss: 0.0194 - val_loss: 0.0207\n",
      "Epoch 34/60\n",
      "100s - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 35/60\n",
      "100s - loss: 0.0191 - val_loss: 0.0206\n",
      "Epoch 36/60\n",
      "98s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 37/60\n",
      "98s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 38/60\n",
      "102s - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 39/60\n",
      "99s - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 40/60\n",
      "99s - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 41/60\n",
      "1052s - loss: 0.0184 - val_loss: 0.0200\n",
      "Epoch 42/60\n",
      "107s - loss: 0.0183 - val_loss: 0.0199\n",
      "Epoch 43/60\n",
      "103s - loss: 0.0182 - val_loss: 0.0198\n",
      "Epoch 44/60\n",
      "104s - loss: 0.0181 - val_loss: 0.0198\n",
      "Epoch 45/60\n",
      "103s - loss: 0.0180 - val_loss: 0.0197\n",
      "Epoch 46/60\n",
      "107s - loss: 0.0179 - val_loss: 0.0197\n",
      "Epoch 47/60\n",
      "99s - loss: 0.0179 - val_loss: 0.0198\n",
      "Epoch 48/60\n",
      "99s - loss: 0.0178 - val_loss: 0.0196\n",
      "Epoch 49/60\n",
      "98s - loss: 0.0177 - val_loss: 0.0195\n",
      "Epoch 50/60\n",
      "99s - loss: 0.0176 - val_loss: 0.0195\n",
      "Epoch 51/60\n",
      "99s - loss: 0.0176 - val_loss: 0.0195\n",
      "Epoch 52/60\n",
      "99s - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 53/60\n",
      "99s - loss: 0.0175 - val_loss: 0.0192\n",
      "Epoch 54/60\n",
      "99s - loss: 0.0174 - val_loss: 0.0193\n",
      "Epoch 55/60\n",
      "99s - loss: 0.0173 - val_loss: 0.0192\n",
      "Epoch 56/60\n",
      "98s - loss: 0.0173 - val_loss: 0.0192\n",
      "Epoch 57/60\n",
      "99s - loss: 0.0172 - val_loss: 0.0191\n",
      "Epoch 58/60\n",
      "98s - loss: 0.0171 - val_loss: 0.0192\n",
      "Epoch 59/60\n",
      "99s - loss: 0.0171 - val_loss: 0.0192\n",
      "Epoch 60/60\n",
      "99s - loss: 0.0170 - val_loss: 0.0190\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('model.h5'):\n",
    "    model = load_model('model.h5')\n",
    "else:\n",
    "    model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          verbose=2,\n",
    "          batch_size=64,\n",
    "          epochs=60)\n",
    "    \n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "During the testing or after deploy the model, to generate the output we will use \"greedy\" generating approach, which is generating one output at a time by maximize softmax score and feed the output back as the next decoder input character. \n",
    "\n",
    "We won't use [beam-search decoding](https://www.quora.com/Why-is-beam-search-required-in-sequence-to-sequence-transduction-using-recurrent-neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(text):\n",
    "    encoder_input = transform(input_encoding, [text.lower()], 20)\n",
    "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
    "    decoder_input[:,0] = START_CHAR_CODE\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
    "        decoder_input[:,i] = output[:,i]\n",
    "    return decoder_input[:,1:]\n",
    "\n",
    "def decode(decoding, sequence):\n",
    "    text = ''\n",
    "    for i in sequence:\n",
    "        if i == 0:\n",
    "            break\n",
    "        text += output_decoding[i]\n",
    "    return text\n",
    "\n",
    "def to_katakana(text):\n",
    "    decoder_output = generate(text)\n",
    "    return decode(output_decoding, decoder_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is trained correctly, typical names should be translate correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James ジェームズ\n",
      "John ジョン\n",
      "Robert ロベルト\n",
      "Mary マリー\n",
      "Patricia パトリシア\n",
      "Linda リンダ\n"
     ]
    }
   ],
   "source": [
    "common_american_names = ['James', 'John', 'Robert', 'Mary', 'Patricia', 'Linda']\n",
    "for name in common_american_names:\n",
    "    print(name, to_katakana(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we train the model with mostly people and places names, some English words may not be written correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コンプーター\n",
      "タクシ\n"
     ]
    }
   ],
   "source": [
    "print(to_katakana('computer'))\n",
    "print(to_katakana('taxi'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
