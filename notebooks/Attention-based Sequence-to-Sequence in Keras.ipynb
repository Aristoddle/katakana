{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "# To import 'katakana' from relative path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from katakana import encoding\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dorogobuzh ドロゴブージ\n",
      "brian cowen ブライアン・カウエン\n",
      "training size 64356\n",
      "validation size 10726\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/joined_titles.csv', header=None)\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "\n",
    "data_input = [s.decode('utf-8').lower() for s in data[0]]\n",
    "data_output = [s.decode('utf-8') for s in data[1]]\n",
    "print(data_input[0], data_output[0])\n",
    "print(data_input[5], data_output[5])\n",
    "\n",
    "data_size = len(data)\n",
    "\n",
    "# We will use the first 0-60th %-tile (60%) of data for the training\n",
    "training_input  = data_input[data_size*0/100:data_size*60/100]\n",
    "training_output = data_output[data_size*0/100:data_size*60/100]\n",
    "\n",
    "# We will use the first 60-70th %-tile (10%) of data for the training\n",
    "validation_input = data_input[data_size*60/100:data_size*70/100]\n",
    "validation_output = data_output[data_size*60/100:data_size*70/100]\n",
    "\n",
    "print('training size', len(training_input))\n",
    "print('validation size', len(validation_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data into Numpy arrays\n",
    "\n",
    "We transform the sequences of characters into sequences of integer IDs. This will be done by using pre-written functions in `encoding` module. \n",
    "- First, `encoding.build_characters_encoding` will build encoding/decoding dictionary from the data. \n",
    "- Then, `encoding.transform` will transform the data into numpy array.\n",
    "\n",
    "Check [the previous notebook](./Writing Katakana using Sequence-to-Sequence in Keras) for the details about the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English character dict size: 54\n",
      "Katakana character dict size: 89\n",
      "encoded_training_input (64356, 20)\n",
      "encoded_training_output (64356, 20)\n",
      "encoded_validation_input (10726, 20)\n",
      "encoded_validation_output (10726, 20)\n"
     ]
    }
   ],
   "source": [
    "input_encoding, input_decoding, input_dict_size = encoding.build_characters_encoding(data_input)\n",
    "output_encoding, output_decoding, output_dict_size = encoding.build_characters_encoding(data_output)\n",
    "\n",
    "print('English character dict size:', input_dict_size)\n",
    "print('Katakana character dict size:', output_dict_size)\n",
    "\n",
    "encoded_training_input = encoding.transform(\n",
    "    input_encoding, training_input, vector_size=INPUT_LENGTH)\n",
    "encoded_training_output = encoding.transform(\n",
    "    output_encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_training_input', encoded_training_input.shape)\n",
    "print('encoded_training_output', encoded_training_output.shape)\n",
    "\n",
    "encoded_validation_input = encoding.transform(\n",
    "    input_encoding, validation_input, vector_size=INPUT_LENGTH)\n",
    "encoded_validation_output = encoding.transform(\n",
    "    output_encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_validation_input', encoded_validation_input.shape)\n",
    "print('encoded_validation_output', encoded_validation_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder / Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder Tensor(\"lstm_5/transpose_2:0\", shape=(?, 20, 64), dtype=float32)\n",
      "encoder_last Tensor(\"strided_slice_2:0\", shape=(?, 64), dtype=float32)\n",
      "decoder Tensor(\"lstm_6/transpose_2:0\", shape=(?, 20, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "encoder = Embedding(input_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = LSTM(64, return_sequences=True, unroll=True)(encoder)\n",
    "encoder_last = encoder[:,-1,:]\n",
    "\n",
    "print('encoder', encoder)\n",
    "print('encoder_last', encoder_last)\n",
    "\n",
    "decoder = Embedding(output_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "decoder = LSTM(64, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
    "\n",
    "print('decoder', decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism\n",
    "\n",
    "Reference: \n",
    "[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf)'s \n",
    "**Global Attention** with **Dot**-based scoring function (Section 3, 3.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention Tensor(\"activation_3/div:0\", shape=(?, 20, 20), dtype=float32)\n",
      "context Tensor(\"dot_6/MatMul:0\", shape=(?, 20, 64), dtype=float32)\n",
      "decoder_combined_context Tensor(\"time_distributed_5/Reshape_1:0\", shape=(?, 20, 64), dtype=float32)\n",
      "decoder_output Tensor(\"time_distributed_6/Reshape_1:0\", shape=(?, 20, 89), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, dot, concatenate\n",
    "\n",
    "scores = dot([decoder, encoder], axes=[2, 2])\n",
    "attention = Activation('softmax')(scores)\n",
    "print('attention', attention)\n",
    "\n",
    "context = dot([attention, encoder], axes=[2,1])\n",
    "print('context', context)\n",
    "\n",
    "#\n",
    "decoder_combined_context = concatenate([context, decoder])\n",
    "decoder_combined_context = TimeDistributed(Dense(64, activation=\"linear\"))(decoder_combined_context)\n",
    "print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "decoder_output = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(decoder_combined_context)\n",
    "print('decoder_output', decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_encoder_input = encoded_training_input\n",
    "training_decoder_input = np.zeros_like(encoded_training_output)\n",
    "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
    "training_decoder_input[:, 0] = encoding.CHAR_CODE_START\n",
    "training_decoder_output = np.eye(output_dict_size)[encoded_training_output.astype('int')]\n",
    "\n",
    "validation_encoder_input = encoded_validation_input\n",
    "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
    "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
    "validation_decoder_input[:, 0] = encoding.CHAR_CODE_START\n",
    "validation_decoder_output = np.eye(output_dict_size)[encoded_validation_output.astype('int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64356 samples, validate on 10726 samples\n",
      "Epoch 1/30\n",
      "90s - loss: 0.0456 - val_loss: 0.0385\n",
      "Epoch 2/30\n",
      "85s - loss: 0.0307 - val_loss: 0.0231\n",
      "Epoch 3/30\n",
      "84s - loss: 0.0204 - val_loss: 0.0186\n",
      "Epoch 4/30\n",
      "89s - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 5/30\n",
      "85s - loss: 0.0165 - val_loss: 0.0162\n",
      "Epoch 6/30\n",
      "89s - loss: 0.0156 - val_loss: 0.0154\n",
      "Epoch 7/30\n",
      "95s - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 8/30\n",
      "93s - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 9/30\n",
      "96s - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 10/30\n",
      "98s - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 11/30\n",
      "97s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 12/30\n",
      "97s - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 13/30\n",
      "98s - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 14/30\n",
      "97s - loss: 0.0127 - val_loss: 0.0132\n",
      "Epoch 15/30\n",
      "99s - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 16/30\n",
      "94s - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 17/30\n",
      "93s - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 18/30\n",
      "93s - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 19/30\n",
      "95s - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 20/30\n",
      "95s - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 21/30\n",
      "96s - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 22/30\n",
      "96s - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 23/30\n",
      "95s - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 24/30\n",
      "92s - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 25/30\n",
      "87s - loss: 0.0114 - val_loss: 0.0124\n",
      "Epoch 26/30\n",
      "87s - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 27/30\n",
      "84s - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 28/30\n",
      "84s - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 29/30\n",
      "86s - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 30/30\n",
      "85s - loss: 0.0111 - val_loss: 0.0123\n",
      "Train on 64356 samples, validate on 10726 samples\n",
      "Epoch 1/5\n",
      "85s - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 2/5\n",
      "85s - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 3/5\n",
      "85s - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 4/5\n",
      "85s - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 5/5\n",
      "85s - loss: 0.0108 - val_loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:2337: UserWarning: Layer lstm_6 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'strided_slice_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'strided_slice_2:0' shape=(?, 64) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('model.h5'):\n",
    "    model = load_model('model.h5')\n",
    "else:\n",
    "    model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          verbose=2, batch_size=64, epochs=30)\n",
    "\n",
    "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          verbose=2, batch_size=64, epochs=5)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James ジェームズ\n",
      "John ジョン\n",
      "Robert ロバート\n",
      "Mary マリー\n",
      "Patricia パトリシア\n",
      "Linda リンダ\n"
     ]
    }
   ],
   "source": [
    "def generate(text):\n",
    "    encoder_input = encoding.transform(input_encoding, [text.lower()], 20)\n",
    "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
    "    decoder_input[:,0] = encoding.CHAR_CODE_START\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
    "        decoder_input[:,i] = output[:,i]\n",
    "    return decoder_input[:,1:]\n",
    "\n",
    "def decode(decoding, sequence):\n",
    "    text = ''\n",
    "    for i in sequence:\n",
    "        if i == 0:\n",
    "            break\n",
    "        text += output_decoding[i]\n",
    "    return text\n",
    "\n",
    "def to_katakana(text):\n",
    "    decoder_output = generate(text)\n",
    "    return decode(output_decoding, decoder_output[0])\n",
    "\n",
    "\n",
    "common_american_names = ['James', 'John', 'Robert', 'Mary', 'Patricia', 'Linda']\n",
    "for name in common_american_names:\n",
    "    print(name, to_katakana(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ペーター\n"
     ]
    }
   ],
   "source": [
    " print(to_katakana('Peter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "バナーナ\n"
     ]
    }
   ],
   "source": [
    "print(to_katakana('Banana'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_5:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'input_6:0' shape=(?, 20) dtype=float32>]\n",
      "<keras.layers.core.Activation object at 0x7f04d948e610>\n",
      "(20, 20)\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs)\n",
    "print(model.layers[7])\n",
    "\n",
    "attention_layer = model.layers[7]\n",
    "attention_model = Model(inputs=model.inputs, outputs=[attention_layer.output])\n",
    "\n",
    "\n",
    "testing_input_word = training_input[199]\n",
    "testing_output_word = training_output[199]\n",
    "\n",
    "\n",
    "testing_encoder_input = encoding.transform(input_encoding, [testing_input_word.lower()], INPUT_LENGTH)\n",
    "testing_decoder_input = np.zeros_like(encoded_training_output)\n",
    "testing_decoder_input[:, 1:] = encoding.transform(output_encoding, [testing_output_word.lower()], OUTPUT_LENGTH -1)\n",
    "testing_decoder_input[:, 0] = encoding.CHAR_CODE_START\n",
    "\n",
    "attention_density = attention_model.predict([\n",
    "    testing_encoder_input,\n",
    "    testing_decoder_input,\n",
    "])[0]\n",
    "\n",
    "print(attention_density.shape)\n",
    "\n",
    "attention_density = attention_density[:len(testing_output_word)+2, :len(testing_input_word)+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04c43ae210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAEuCAYAAACznnnMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACAYyhEAACAYyhEAACAY/4fVkPnX0eDbIkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04c43ae3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10,5))\n",
    "seaborn.set(font='TakaoPGothic')\n",
    "ax = seaborn.heatmap(attention_density, \n",
    "                xticklabels=[w for w in testing_input_word],\n",
    "                yticklabels=[w for w in testing_output_word])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
