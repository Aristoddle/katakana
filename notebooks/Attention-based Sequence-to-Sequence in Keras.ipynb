{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from katakana import encoding\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dorogobuzh ドロゴブージ\n",
      "brian cowen ブライアン・カウエン\n",
      "training size 64356\n",
      "validation size 10726\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/joined_titles.csv', header=None)\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "\n",
    "data_input = [s.decode('utf-8').lower() for s in data[0]]\n",
    "data_output = [s.decode('utf-8') for s in data[1]]\n",
    "print(data_input[0], data_output[0])\n",
    "print(data_input[5], data_output[5])\n",
    "\n",
    "data_size = len(data)\n",
    "\n",
    "# We will use the first 0-60th %-tile (60%) of data for the training\n",
    "training_input  = data_input[data_size*0/100:data_size*60/100]\n",
    "training_output = data_output[data_size*0/100:data_size*60/100]\n",
    "\n",
    "# We will use the first 60-70th %-tile (10%) of data for the training\n",
    "validation_input = data_input[data_size*60/100:data_size*70/100]\n",
    "validation_output = data_output[data_size*60/100:data_size*70/100]\n",
    "\n",
    "print('training size', len(training_input))\n",
    "print('validation size', len(validation_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data into Numpy arrays\n",
    "\n",
    "We transform the sequences of characters into sequences of integer IDs. This will be done by using pre-written functions in `encoding` module. \n",
    "- First, `encoding.build_characters_encoding` will build encoding/decoding dictionary from the data. \n",
    "- Then, `encoding.transform` will transform the data into numpy array.\n",
    "\n",
    "Check [the previous notebook](./Writing Katakana using Sequence-to-Sequence in Keras) for the details about the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English character dict size: 54\n",
      "Katakana character dict size: 89\n",
      "encoded_training_input (64356, 20)\n",
      "encoded_training_output (64356, 15)\n",
      "encoded_validation_input (10726, 20)\n",
      "encoded_validation_output (10726, 15)\n"
     ]
    }
   ],
   "source": [
    "input_encoding, input_decoding, input_dict_size = encoding.build_characters_encoding(data_input)\n",
    "output_encoding, output_decoding, output_dict_size = encoding.build_characters_encoding(data_output)\n",
    "\n",
    "print('English character dict size:', input_dict_size)\n",
    "print('Katakana character dict size:', output_dict_size)\n",
    "\n",
    "encoded_training_input = encoding.transform(\n",
    "    input_encoding, training_input, vector_size=INPUT_LENGTH)\n",
    "encoded_training_output = encoding.transform(\n",
    "    output_encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_training_input', encoded_training_input.shape)\n",
    "print('encoded_training_output', encoded_training_output.shape)\n",
    "\n",
    "encoded_validation_input = encoding.transform(\n",
    "    input_encoding, validation_input, vector_size=INPUT_LENGTH)\n",
    "encoded_validation_output = encoding.transform(\n",
    "    output_encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_validation_input', encoded_validation_input.shape)\n",
    "print('encoded_validation_output', encoded_validation_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder / Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder Tensor(\"lstm_86/transpose_2:0\", shape=(?, 20, 64), dtype=float32)\n",
      "encoder_last Tensor(\"strided_slice_40:0\", shape=(?, 64), dtype=float32)\n",
      "decoder Tensor(\"lstm_87/transpose_2:0\", shape=(?, 15, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "encoder = Embedding(input_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = LSTM(64, return_sequences=True, unroll=True)(encoder)\n",
    "encoder_last = encoder[:,-1,:]\n",
    "\n",
    "print('encoder', encoder)\n",
    "print('encoder_last', encoder_last)\n",
    "\n",
    "decoder = Embedding(output_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "decoder = LSTM(64, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
    "\n",
    "print('decoder', decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism\n",
    "\n",
    "Reference: \n",
    "[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf)'s \n",
    "**Global Attention** with **Dot**-based scoring function (Section 3, 3.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention Tensor(\"activation_3/div:0\", shape=(?, 15, 20), dtype=float32)\n",
      "context Tensor(\"dot_71/MatMul:0\", shape=(?, 15, 64), dtype=float32)\n",
      "decoder_combined_context Tensor(\"time_distributed_13/Reshape_1:0\", shape=(?, 15, 64), dtype=float32)\n",
      "decoder_output Tensor(\"time_distributed_14/Reshape_1:0\", shape=(?, 15, 89), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, dot, concatenate\n",
    "\n",
    "scores = dot([decoder, encoder], axes=[2, 2])\n",
    "attention = Activation('softmax')(scores)\n",
    "print('attention', attention)\n",
    "\n",
    "context = dot([attention, encoder], axes=[2,1])\n",
    "print('context', context)\n",
    "\n",
    "#\n",
    "decoder_combined_context = concatenate([context, decoder])\n",
    "decoder_combined_context = TimeDistributed(Dense(64, activation=\"linear\"))(decoder_combined_context)\n",
    "print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "decoder_output = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(decoder_combined_context)\n",
    "print('decoder_output', decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_encoder_input = encoded_training_input\n",
    "training_decoder_input = np.zeros_like(encoded_training_output)\n",
    "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
    "training_decoder_input[:, 0] = encoding.CHAR_CODE_START\n",
    "training_decoder_output = np.eye(output_dict_size)[encoded_training_output.astype('int')]\n",
    "\n",
    "validation_encoder_input = encoded_validation_input\n",
    "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
    "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
    "validation_decoder_input[:, 0] = encoding.CHAR_CODE_START\n",
    "validation_decoder_output = np.eye(output_dict_size)[encoded_validation_output.astype('int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64356 samples, validate on 10726 samples\n",
      "Epoch 1/10\n",
      "153s - loss: 0.0456 - val_loss: 0.0397\n",
      "Epoch 2/10\n",
      "106s - loss: 0.0349 - val_loss: 0.0292\n",
      "Epoch 3/10\n",
      "113s - loss: 0.0232 - val_loss: 0.0197\n",
      "Epoch 4/10\n",
      "127s - loss: 0.0183 - val_loss: 0.0173\n",
      "Epoch 5/10\n",
      "117s - loss: 0.0166 - val_loss: 0.0161\n",
      "Epoch 6/10\n",
      "117s - loss: 0.0155 - val_loss: 0.0153\n",
      "Epoch 7/10\n",
      "104s - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 8/10\n",
      "132s - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 9/10\n",
      "119s - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 10/10\n",
      "119s - loss: 0.0134 - val_loss: 0.0137\n",
      "Train on 64356 samples, validate on 10726 samples\n",
      "Epoch 1/5\n",
      "108s - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 2/5\n",
      "107s - loss: 0.0128 - val_loss: 0.0133\n",
      "Epoch 3/5\n",
      "110s - loss: 0.0126 - val_loss: 0.0131\n",
      "Epoch 4/5\n",
      "106s - loss: 0.0124 - val_loss: 0.0130\n",
      "Epoch 5/5\n",
      "108s - loss: 0.0123 - val_loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wanasit/VirtualEnv/nlp/lib/python2.7/site-packages/keras/engine/topology.py:2341: UserWarning: Layer lstm_87 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'strided_slice_40:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'strided_slice_40:0' shape=(?, 64) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('model.h5'):\n",
    "    model = load_model('model.h5')\n",
    "else:\n",
    "    model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          verbose=2, batch_size=64, epochs=10)\n",
    "\n",
    "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          verbose=2, batch_size=64, epochs=5)\n",
    "\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
